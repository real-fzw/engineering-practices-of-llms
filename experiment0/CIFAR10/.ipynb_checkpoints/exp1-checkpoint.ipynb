{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d97327-3dea-49b1-9186-4299a838397a",
   "metadata": {},
   "source": [
    "## 加载数据：Hello, CIFAR-10!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52cc097-5f5d-4d0b-a65a-0af58d46cd60",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "我们先从最常见的计算机视觉入门数据集之一开始：CIFAR-10。它包含 60000 张 32×32 的彩色小图片，分属于 10 个类别（飞机、汽车、猫、狗……）。\n",
    "\n",
    "来看第一段代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453744f-1910-437a-a279-36ba8324132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='../data/cifar-10-batches-py', train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=False)\n",
    "test_data = torchvision.datasets.CIFAR10(root='../data/cifar-10-batches-py', train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead58cf-a9e1-4c70-83d5-139038c0f62c",
   "metadata": {},
   "source": [
    "逐行拆解一下：\n",
    "\n",
    "import torch, import torchvision, import torch.nn as nn：\n",
    "导入 PyTorch 核心库、计算机视觉工具包 torchvision，以及神经网络模块 torch.nn。\n",
    "\n",
    "torchvision.datasets.CIFAR10(...)：\n",
    "download=True会在路径下没有数据集的时候去尝试下载。我们需要提前下载数据集放到指定路径下。\n",
    "\n",
    "train=True：加载训练集。\n",
    "\n",
    "train=False：加载测试集。\n",
    "\n",
    "transform=torchvision.transforms.ToTensor()：把 PIL 图片转换成 PyTorch 的 Tensor，并把像素归一化到 [0, 1]。\n",
    "\n",
    "DataLoader(...)：\n",
    "DataLoader 帮你自动按批次（batch）打包数据、打乱顺序等。\n",
    "\n",
    "batch_size=64 表示每次训练从数据集中取 64 张图片组成一个 batch。\n",
    "\n",
    "最后我们打印出训练集和测试集的长度，验证数据加载是否成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58df40-14a0-4225-8671-a1121c95f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "print(\"训练集的长度:{}\".format(len(train_data)))\n",
    "print(\"测试集的长度:{}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581421a-f1ff-4f5a-b834-b874f38b8a68",
   "metadata": {},
   "source": [
    "## 搭建一个简单的卷积神经网络\n",
    "\n",
    "既然有了数据，我们需要一个模型来“看图识物”。下面是函数定义：\n",
    "\n",
    "nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)：卷积层，用于提取特征。\n",
    "\n",
    "    in_channels：输入的通道数（对于彩色图像是3）。\n",
    "\n",
    "    out_channels：输出的通道数。\n",
    "\n",
    "    kernel_size：卷积核的大小。\n",
    "\n",
    "    stride：步长，决定每次卷积滑动的步幅。\n",
    "\n",
    "    padding：填充，确保输入和输出的空间维度一致。\n",
    "\n",
    "nn.MaxPool2d(kernel_size)：最大池化层，用于下采样，减少特征图的空间大小。\n",
    "\n",
    "    kernel_size：池化窗口的大小，通常是 2x2 或 3x3。\n",
    "\n",
    "nn.Flatten()：展平层，将多维的特征图展平成一维，以便输入到全连接层。\n",
    "\n",
    "nn.Linear(in_features, out_features)：全连接层，输入与输出都是一维向量。\n",
    "\n",
    "    in_features：输入的特征数量。\n",
    "\n",
    "    out_features：输出的特征数量。\n",
    "\n",
    "# Your Turn！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c992524-56e2-4ca5-b926-993328f8ee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # 使用 nn.Sequential 按顺序堆叠层\n",
    "        self.model = nn.Sequential(\n",
    "            # TODO 1: 第一层卷积层（输入3通道，输出32通道，卷积核5x5，步长1，padding2）\n",
    "\n",
    "            # TODO 2: 第一层最大池化层（池化窗口大小2x2）\n",
    "\n",
    "            # TODO 3: 第二层卷积层（输入32通道，输出32通道，卷积核5x5）\n",
    "\n",
    "            # TODO 4: 第二层最大池化层（池化窗口大小2x2）\n",
    "\n",
    "            # TODO 5: 第三层卷积层（输入32通道，输出64通道，卷积核5x5）\n",
    "\n",
    "            # TODO 6: 第三层最大池化层（池化窗口大小2x2）\n",
    "\n",
    "            # TODO 7: 展平层，将多维的特征图展平成一维\n",
    "\n",
    "            # TODO 8: 第一个全连接层（输入64*4*4，输出64）\n",
    "            \n",
    "            # TODO 9: 第二个全连接层（输入64，输出10）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播通过 `self.model` 进行\n",
    "        return self.model(x)\n",
    "\n",
    "# 测试模型结构\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1497d7a-1182-4d69-9b06-896b6cc5e205",
   "metadata": {},
   "source": [
    "这里发生了什么？\n",
    "\n",
    "class Model(nn.Module)：\n",
    "在 PyTorch 中，所有神经网络模型都应该继承自 nn.Module。\n",
    "\n",
    "forward 函数：\n",
    "定义前向传播的计算逻辑。在这里，我们直接把输入 x 丢进 self.model 里。\n",
    "\n",
    "device = torch.device('cpu') 和 model.to(device)：\n",
    "把模型放到指定的设备上。现在用的是 CPU，如果你有 GPU，也可以改成 'cuda'。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1054f8-ae97-4872-a281-069bb321aa4d",
   "metadata": {},
   "source": [
    "## 损失函数和优化器：告诉模型“哪里错了”\n",
    "\n",
    "有了模型，还需要告诉它 “预测错了要怎么惩罚”，以及 “如何更新自己”。\n",
    "\n",
    "| 损失函数                 | 适用场景            \n",
    "| ------------------------ | --------------- \n",
    "| `nn.CrossEntropyLoss`    | 多分类问题           \n",
    "| `nn.MSELoss`             | 回归问题           \n",
    "| `nn.BCELoss`             | 二分类问题（概率值输入）    \n",
    "| `nn.BCEWithLogitsLoss`   | 二分类问题（logits输入） \n",
    "| `nn.NLLLoss`             | 多分类问题（log概率）    \n",
    "| `nn.SmoothL1Loss`        | 回归问题（鲁棒性强）      \n",
    "| `nn.KLDivLoss`           | 概率分布相似性（VAE等）   \n",
    "| `nn.CosineEmbeddingLoss` | 相似度学习（度量学习）     \n",
    "| `nn.MarginRankingLoss`   | 排序问题            \n",
    "| `nn.HingeEmbeddingLoss`  | 支持向量机（SVM）训练    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271628f-09e1-46fe-81f0-a3e2796a0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2c9783-3811-4693-984b-72fe9cb7ba4b",
   "metadata": {},
   "source": [
    "nn.CrossEntropyLoss()：\n",
    "这是分类问题最常用的损失函数之一。它会比较模型输出的类别分布和真实标签之间的差异，差异越大，损失越高。\n",
    "\n",
    "你也可以尝试换用其他损失函数\n",
    "\n",
    "optim.SGD(...)：\n",
    "使用随机梯度下降（Stochastic Gradient Descent）来更新参数。\n",
    "\n",
    "model.parameters()：告诉优化器要更新哪些参数（就是模型里的卷积核和权重）。\n",
    "\n",
    "lr=0.01：学习率，控制每次参数更新的步伐大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe2af9e-7798-41f5-9d14-9859dc427e0d",
   "metadata": {},
   "source": [
    "## 训练循环：让模型一轮一轮变聪明\n",
    "\n",
    "核心训练逻辑在下面这段代码中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780499f-aa88-4546-bf88-99a92c0e778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1294233-3eab-4e4e-afbe-46a3257f1903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "num_epochs = 30\n",
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "save_dir = \"../data/models/CIFAR\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    accuracy = 100 * correct_predictions / total_samples\n",
    "\n",
    "    losses.append(avg_loss)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # 保存模型\n",
    "    model_save_path = os.path.join(save_dir, f\"model_epoch_{epoch+1}.pth\")\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"模型已保存为 {model_save_path}\")\n",
    "\n",
    "    # ===== 关键：在 Jupyter 中动态更新图像 =====\n",
    "    clear_output(wait=True)     # 清空上一轮的输出（包括图像和文字）\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss 曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(losses)+1), losses)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "\n",
    "    # Accuracy 曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(accuracies)+1), accuracies)\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # ===== 关键结束 =====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae305fa-4026-4bb3-b381-259dda641a9c",
   "metadata": {},
   "source": [
    "一层一层看：\n",
    "\n",
    "for epoch in range(num_epochs):：\n",
    "一共训练 30 轮（epoch）。一轮就是完整地扫一遍训练集。\n",
    "\n",
    "model.train()：\n",
    "把模型设置成训练模式。有些层（如 Dropout、BatchNorm）在训练和测试时行为不同，这个调用可以确保它们处于“训练状态”。\n",
    "\n",
    "for inputs, labels in train_dataloader:：\n",
    "从 DataLoader 中一批一批取出图片和对应的标签。\n",
    "\n",
    "optimizer.zero_grad()：\n",
    "在每次反向传播前，先把上一次累积的梯度清零。\n",
    "\n",
    "前向传播：\n",
    "\n",
    "outputs = model(inputs)\n",
    "loss = criterion(outputs, labels)\n",
    "\n",
    "\n",
    "outputs 的形状通常是 [batch_size, 10]，每一行是对 10 个类别的预测。\n",
    "\n",
    "criterion 会比较预测和标签，返回一个标量损失。\n",
    "\n",
    "反向传播 & 参数更新：\n",
    "\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "loss.backward()：自动求出每个参数的梯度。\n",
    "\n",
    "optimizer.step()：根据梯度更新参数，让模型在下一次预测时稍微聪明一点。\n",
    "\n",
    "统计指标：\n",
    "\n",
    "running_loss += loss.item()：记录这一轮的总损失。\n",
    "\n",
    "torch.max(outputs, 1)：找出每行中概率最大的那个类别，作为模型的预测结果。\n",
    "\n",
    "(predicted == labels).sum().item()：计算这一批中有多少预测正确。\n",
    "\n",
    "最后计算平均损失 avg_loss 和准确率 accuracy 并打印出来。\n",
    "\n",
    "## 保存模型：留住训练成果\n",
    "\n",
    "训练完一轮，我们希望把模型的状态保存下来，这样以后可以直接加载使用，而不必每次都从头再训一遍。\n",
    "\n",
    "model.state_dict()：\n",
    "只保存模型中的参数（权重和偏置），而不是整个类定义。\n",
    "\n",
    "torch.save(...)：\n",
    "把这些参数写入到 .pth 文件中。\n",
    "文件名里加上 epoch，可以方便地在不同训练阶段保存多个版本，例如 model_epoch_1.pth、model_epoch_10.pth。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c121539d-24d4-4066-a2e5-0de535983288",
   "metadata": {},
   "source": [
    "## 使用训练好的模型做预测\n",
    "\n",
    "训练和保存都搞定了，接下来我们想看看：模型能不能正确识别一张从未见过的测试图片？\n",
    "\n",
    "我们重新定义同样结构的模型（加载参数时结构必须一致）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804a28f-0ab8-45ea-bc59-e4be524ad872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "import torch\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# 定义模型\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # 使用 nn.Sequential 按顺序堆叠层\n",
    "        self.model = nn.Sequential(\n",
    "            # 这里复用你之前定义并训练的模型\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "# 定义CIFAR-10类别\n",
    "CIFAR10_CLASSES = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# 加载CIFAR-10测试集\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32, 32)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d7cc5-036e-44cd-83f3-9f8d0b5d2f28",
   "metadata": {},
   "source": [
    "这里我们做了两件事：\n",
    "\n",
    "再次使用 torchvision.datasets.CIFAR10 加载测试集；\n",
    "\n",
    "利用 transform 确保图片大小为 32×32，并转换为 Tensor。\n",
    "\n",
    "## 随机选一张图来看看\n",
    "\n",
    "我们从测试集中随机选一张图片，展示它，并让模型来猜一猜："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08249e67-3059-4d44-81dc-33082b57c2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.CIFAR10(root='../data/cifar-10-batches-py', train=False, transform=transform, download=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# 随机选取一张测试集中的图片\n",
    "random_idx = random.randint(0, len(test_data) - 1)  # 随机索引\n",
    "image, label = test_data[random_idx]  # 获取该索引的图片和标签\n",
    "\n",
    "# 将 Tensor 转换回 PIL Image 以便显示\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "image_pil = to_pil(image)\n",
    "# 调整图片尺寸\n",
    "image_pil = image_pil.resize((256, 256))  # 调整图片大小，(512, 512) 是示例，可以根据需要修改\n",
    "\n",
    "# 显示调整后的图片\n",
    "image_pil.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cecde3-1652-4564-a9db-f6a879489333",
   "metadata": {},
   "source": [
    "## 加载模型参数并进行推理\n",
    "\n",
    "最后，加载我们之前保存的模型权重，并对刚才选出的那张图片进行分类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ce8c4-2cb1-4442-be8f-9547dddef25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = Model()  # 先初始化模型\n",
    "model.load_state_dict(torch.load('../data/models/CIFAR/model_epoch_5.pth'))  # 加载模型参数\n",
    "\n",
    "# 调整图片形状\n",
    "image = image.unsqueeze(0)  # 增加一个批次维度\n",
    "\n",
    "# 设置模型为评估模式\n",
    "model.eval()\n",
    "\n",
    "# 不计算梯度\n",
    "with torch.no_grad():\n",
    "    # 如果使用GPU，确保模型和输入都在同一个设备上\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    image = image.to(device)\n",
    "    \n",
    "    # 前向推理\n",
    "    output = model(image)\n",
    "\n",
    "# 输出预测结果\n",
    "predicted_class = output.argmax(1).item()  # 获取预测类别的索引\n",
    "print(f\"实际标签: {CIFAR10_CLASSES[label]}\")\n",
    "print(f\"预测类别: {CIFAR10_CLASSES[predicted_class]}\")  # 输出预测的类别名称"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd5ad5-9e0d-4bc7-9b30-750599fca389",
   "metadata": {},
   "source": [
    "## 轮到你动手了！\n",
    "\n",
    "现在你已经看到一个完整的 PyTorch 视觉项目从 数据加载 → 模型定义 → 训练与保存 → 加载模型做推理 的完整流程。接下来你可以尝试：\n",
    "\n",
    "#### 1.修改网络结构（例如增加卷积层、增加通道数）看看准确率会不会提高；\n",
    "\n",
    "#### 2.调整 num_epochs 或者 learning rate，感受训练曲线的变化；\n",
    "\n",
    "#### 3.在推理阶段多随机几张图片，观察模型容易搞混哪些类别。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
